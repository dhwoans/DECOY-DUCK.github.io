## 캐시 메모리

CPU의 처리속도와 메모리의 엑세스 속도의 격차를 극복하지 못하면 CPU 처리 속도가 아무리 뛰어나더라도 제대로된 성능을 내지 못한다. 이런 속도 차이를 극복하기 위해 CPU가 앞으로 사용될 것이라 예상되는 데이터를 임시 저장소에 저장하게 되는데 이 임시 저장소를 `캐시 cache`라고 한다.

<img width="719" alt="image" src="https://user-images.githubusercontent.com/51963264/193691300-147cebfc-5b56-4a56-bf1e-e8a580f589d5.png">

캐시는 SRAM을 사용하기 때문에 DRAM을 사용하는 주기억 장치보다 엑세스 시간이 짧다. 최근에는 CPU칩 내부에 캐시를 포함시키는데 이와 같은 구조에서 CPU는 필요한 데이터를 얻기 위해 L1 캐시, L2캐시, 주기억 장치 순으로 조사하게 된다.

CPU가 기억장치에 데이터를 읽으려고 할 경우 먼저 해당 데이터가 캐시에 있는 지 먼저 살펴본다. 만약 원하는 데이터를 찾았다면 `히트`되었다고 하며 즉시 데이터를 읽어 들인다. 반면 데이터가 없다면 주기억 장치에서 캐시로 데이터를 적재한 후 읽어들인다. 프로세스 실행 동안 이러한 과정을 반복한다.


### 캐시 적중률

캐시 히트가 되는 비율을 `캐시 적중률`이라고 하는데 결국 캐시를 사용하면서 얻을 수 있는 이득은 이 캐시 적중률에 달려있다. 

캐시 적중률을 높이는 방법에는 단순히 용량을 늘리는 것이 있는데 용량이 커지면 더 많은 데이터를 미리 가져올수 있기 때문이다. 하지만 용량을 늘린다는 것은 물리적 크기가 커진다는 것을 의미하고 이는 곧 비용이 증가한다는 뜻도 된다. 그래서 용량을 늘릴때 공간적 ,비용적인 제약을 고려해야 한다.

캐시 적중률을 높이는 또 다른 방법은 앞으로 `많이 사용될 데이터를 예측`하는 것이다. 이것은 연구를 통해서 일반적으로 메모리를 참조할 때 한정된 영역에서 이루어 지는 경향이 있다는 것을 발견했고 이러한 현상을 지역성 원리로 설명하고 있다. 지역성 원리는 공간 지역성과 시간 지역성으로 나뉜다.

`공간 지역성`

기억 장치 내 서로 인접하게 저장되어 있는 데이터는 연속적으로 엑세스될 확률이  높아지는 특성.

`시간 지역성`

최근에 엑세스된 데이터가 다시 엑세스될 확률이 높아지는 특성

### 캐시 정책

캐시 메모리를 설계하면서 몇가지 고려사항이 있다. 예를들어 주기억장치의 데이터를 캐시 메모리에서 어떤 방식으로 가져올것인가, 캐시메모리가 다 찼을때 어떻게 할것인가, 케시에 있는 데이터가 변경될때 어떻게 해야할 것인가 등을 생각해볼 수 있을 것이다. 

### 배치 정책

![image](https://user-images.githubusercontent.com/51963264/195114241-44f9d1c5-4504-41c0-912e-b1115e6c4cd5.png)

CPU가 캐시 메모리의 데이터를 읽으려고 할 경우 두가지 상황을 고려해 볼 수 있다.

- 캐시 히트가 발생한 경우
- 캐시 미스가 발생한 경우

이때 캐시 미스가 발생할 경우 주기억장치에서 데이터를 캐시메모리로 가져오게 되는데 다양한 매핑기술을 사용해서 매핑을 수행할수 있다.

이때 블록은 주기억 장치와 캐시 메모리사이에서 이동되는 데이터의 단위로 결국 매핑은 이 블록이 어느 캐시라인에 적재되는지에 관한 것이다.

`직접 매핑(Direct Mapping)`:

주기억 장치의 블록은 정해진 하나의 캐시 라인에만 들어갈 수 있다.   

`완전 연관 매핑(Fully Associative Mapping)`:

주기억 장치의 블록은 정해진 어떤 캐시 라인에도 들어갈 수 있다.

`세트 연관 매핑(Set Associative Mapping)`:

개시 라인들을 세트로 나눠 주기억 장치의 블록은 세트 하나만 들어갈 수 있다.


### 교체 정책

캐시에 있는 데이터가 다 채워진 상태에서 새로운 데이터를 채울 경우 저장된 블록 중 하나를 교체해야 한다.

`FIFO` : 먼저 들어온 page를 교체한다. 

`LRU(Least Recently Used)` : 

사용되지 않은 것 중 가장 오래된 블록을 교체한다. 가장 효과적

`LFU(Least Frequently Used)` : 

사용 빈도가 적은 블록을 교체한다. 사용 빈도가 적은 page가 여러개이면 LRU로 처리함. 

### 쓰기 정책


캐시에 있는 데이터가 변경될 경우 그 내용을 주기억 장치에도 반영해야 할 필요가 있다. 이때 갱신 시기와 방법을 결정하는 것을 `쓰기 정책`이라 한다. 쓰기 정책에는 `즉시 쓰기`와 `지연 쓰기`가 있다.

`즉시 쓰기 write through`

즉시 쓰기는 캐시에 변경이 있을 때 즉시 메모리에 반영하는 방식이다. 메모리와의 빈번한 전송으로 성능이 느려질 수 있지만 메모리에 최신값이 항상 유지 된다.

`지연 쓰기 write back`

지연 쓰기는 캐시에 변경이 있을 때 변경된 내용을 모아 주기적으로 반영하는 방식이다.